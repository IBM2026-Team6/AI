[LiveCoach AI Script]
Total Time: 58s
==========================================

Part 1: Slide 1 (31s)
이번 슬라이드는 **Language-Specific Neurons**에 대한 두 편의 논문을 소개합니다. 첫 번째 논문은 대형 언어 모델(LLM)이 다국어 처리 능력을 갖추는 핵심 메커니즘을 분석한 연구로, LLaMA-2, BLOOM, Mistral 등의 모델에서 언어별 특화 뉴런(language-specific neurons)을 발견했습니다. 특히 상위/하위 레이어에 집중된 이 뉴런들을 활성화/비활성화함으로써 출력 언어를 제어할 수 있음을 실험적으로 증명했죠. 두 번째 논문은 정보 이득과 분산 기반의 특징 선택 방법을 제안하며, 텍스트 분류에서 중복성을 줄이면서도 정보 손실을 최소화하는 기법을 다룹니다. 두 연구 모두 모델의 효율성과 성능 향상에 중요한 통찰을 제공합니다.

------------------------------------------

Part 2: Slide 2 (27s)
이번 슬라이드에서는 언어별 뉴런 추출 방법과 성능 평가 결과를 설명드리겠습니다.  
첫 번째로, 기존 논문에서는 언어별 활성화 확률을 기반으로 뉴런을 선택했습니다.  
두 번째로, 저희는 MMR 기반 뉴런 선택 방식을 도입했는데요. 정보 획득(Relevance)과 뉴런 간 유사성(Similarity)을 동시에 고려해 최적의 뉴런을 선정합니다.  
마지막으로, MMR 방식으로 선택된 뉴런을 비활성화했을 때 PPL(Perplexity) 점수를 측정했습니다.  
실험 결과, MMR 기반 선택이 기존 방식보다 언어별 특성을 더 잘 보존하면서도 성능 저하를 최소화하는 것으로 나타났습니다.

------------------------------------------

