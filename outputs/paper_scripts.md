# 발표 대본: paper

- extract: upstage_document_parse (ocr=force)
- RAG top_k: 6

## Slide 1 (page=0)

- 슬라이드 대본:  
"정보팀에서 진행한 (주)신우하이텍의 데이터 기반 품질 불량 근원 분석 및 최적화 프로젝트 결과를 보고드리겠습니다. 본 프로젝트는 제조 공정에서 발생하는 품질 문제의 근본 원인을 데이터 분석을 통해 규명하고, 이를 기반으로 공정 최적화 방안을 제시하는 것을 목표로 했습니다. 분석 결과를 바탕으로 한 개선 전략은 품질 향상과 비용 절감에 기여할 것으로 기대됩니다."

- 핵심 메시지 3개:  
1. 데이터 분석을 통해 품질 불량의 근본 원인을 체계적으로 규명  
2. 분석 결과를 바탕으로 공정 최적화 방안 제시  
3. 품질 향상과 비용 절감을 동시에 달성하는 솔루션 개발  

- 예상 질문 2개 + 답변:  
Q1) 품질 불량 원인 분석 시 어떤 데이터 소스를 주로 활용했나요?  
A1) 생산 라인 센서 데이터, 불량품 이력, 공정 파라미터 로그 등 내부 데이터를 종합적으로 분석해 근본 원인을 도출했습니다.  

Q2) 최적화 방안의 구체적인 실행 계획은 어떻게 되나요?  
A2) 분석 결과를 바탕으로 단계별 개선 로드맵을 수립 중이며, 우선 적용 가능한 항목부터 시범 운영 후 전사적 확대를 계획하고 있습니다.

---

## Slide 2 (page=1)

- 슬라이드 대본:  
"안녕하세요. **SHINWOO HITEC**은 차량용 연료 필터, 오일 필터 등을 제조하는 기업입니다. 현재 **스마트 팩토리 기초 단계**에서 데이터 수집 및 데이터베이스 구축 인프라를 1단계 목표로 진행 중입니다. 이를 통해 **공정 데이터 자동 송수신 시스템 구축**, **데이터 기반 공장 운영 최적화**, **맞춤형 스마트공장 SW 탐색**을 제안 목표로 설정했습니다. 감사합니다."

- 핵심 메시지 3개:  
1. SHINWOO HITEC은 차량용 필터 제조 기업이다.  
2. 스마트 팩토리 1단계 목표는 데이터 수집 및 데이터베이스 인프라 구축이다.  
3. 제안 목표는 공정 데이터 시스템화, 운영 최적화, 맞춤형 SW 도입이다.  

- 예상 질문 2개 + 답변:  
Q1) 스마트 팩토리 1단계 이후 계획은 무엇인가요?  
A1) 현재 슬라이드에는 1단계 목표만 명시되어 있으며, 이후 단계에 대한 구체적 내용은 공개되지 않았습니다.  

Q2) 데이터 기반 운영 최적화의 구체적 사례는?  
A2) 발표 자료에는 세부 사례가 제시되지 않았으나, 공정 데이터 자동화와 SW 도입을 통해 효율성을 높일 것으로 예상됩니다.

---

## Slide 3 (page=2)

- 슬라이드 대본:  
"현재 슬라이드에서는 CNC 공정의 주요 단계를 분석하고 있습니다. 먼저 단조품 공정에서는 원소재 입고부터 단조, 열처리, 공급사 검사, 입고 및 라인 투입까지 3단계로 진행됩니다. 다음으로 10번 공정은 외경 척킹과 내경/나사 가공을 중심으로 제품 세팅, 정밀 가공, 품질 검사의 3단계로 구성됩니다. 마지막으로 20번 공정은 LPG OUT부 가공 및 완성 단계로, 척킹 및 세팅, 정밀 가공, 품질 검사를 거쳐 최종 제품이 완성됩니다. 각 공정별 핵심 프로세스와 검사 포인트를 시각적으로 확인할 수 있습니다."

- 핵심 메시지 3개:  
1. CNC 공정은 단조품, 10번 공정, 20번 공정의 3가지 주요 단계로 구성된다.  
2. 각 공정은 단계별 검사 프로세스를 포함하여 품질 관리를 강화한다.  
3. 공정별 척킹 포인트와 가공 기준이 명확히 정의되어 있다.  

- 예상 질문 2개 + 답변:  
Q1) 단조품 공정에서 공급사 자체 검사의 주요 항목은 무엇인가요?  
A1) 슬라이드 텍스트에는 구체적인 검사 항목이 명시되지 않았으나, 일반적으로 치수 정확도, 표면 결함, 기계적 특성 등을 확인합니다.  

Q2) 10번 공정과 20번 공정의 품질 검사 기준은 동일한가요?  
A2) 슬라이드 상에서는 두 공정의 검사 단계가 유사하게 기술되었으나, 가공 부위(외경/내경 vs LPG OUT부)에 따라 검사 기준이 상이할 수 있습니다. 구체적인 기준은 추가 자료가 필요합니다.

---

## Slide 4 (page=3)

- 슬라이드 대본:  
"현재 설비 데이터는 자동 송수신이 되지 않고 수동으로 수집되는 환경입니다. 또한 FANUC 장비와의 통신을 위한 프로토콜이 구축되지 않아 데이터 활용에 제약이 있습니다. 하지만 신우 하이텍 이관수 전무님과의 논의를 통해 기술적 가능성을 확인했으며, KAMP Dataset 구조가 현 데이터 형태와 일치함을 확인했습니다. 따라서 프로젝트 일정 준수를 위해 KAMP Dataset을 활용하기로 결정했습니다."

- 핵심 메시지 3개:  
1. 설비 데이터는 수동 수집 중이며 자동 송수신 시스템 미구축  
2. KAMP Dataset 구조가 신우 하이텍 데이터와 호환 가능  
3. 일정 준수를 위해 KAMP Dataset 활용 결정  

- 예상 질문 2개 + 답변:  
Q1) FANUC 통신 프로토콜 구축은 왜 진행하지 않았나요?  
A1) 프로토콜 구축에는 시간이 소요되며, 프로젝트 일정 상 KAMP Dataset 활용이 더 효율적이라고 판단했기 때문입니다.  

Q2) KAMP Dataset 사용 시 데이터 정확도 문제는 없나요?  
A2) 최면중 멘토 자문을 통해 데이터 구조 일치를 확인했으며, KAMP Dataset이 현재 데이터 형태와 호환되므로 문제 없을 것으로 예상됩니다.

---

## Slide 5 (page=4)

- 슬라이드 대본:  
"03 데이터 분석 및 모델링 섹션의 첫 번째 주제인 '데이터 현황'을 설명드리겠습니다.  
현재 데이터셋은 총 18,805개의 샘플과 48개의 수치형 피처로 구성되어 있습니다. 모든 피처가 float 또는 int 타입이며 결측값이 없어 별도의 전처리가 필요하지 않습니다. 또한 정상과 불량 클래스가 약 50:50으로 균형 잡혀 있어 클래스 불균형 문제도 발생하지 않습니다.  
데이터 출처는 중소벤처기업부와 KAMP에서 제공한 CNC 머신 AI 데이터셋이며, 2020년 12월 공개된 공신력 있는 자료입니다."

- 핵심 메시지 3개:  
1. 18,805개 샘플과 48개 수치형 피처로 구성된 전처리 불필요 데이터셋  
2. 정상/불량 클래스 50:50 균형으로 클래스 불균형 문제 없음  
3. 중소벤처기업부 및 KAMP에서 제공한 공신력 있는 CNC 머신 데이터셋  

- 예상 질문 2개 + 답변:  
Q1) 피처 간 상관관계 분석은 진행되었나요?  
A1) 현재 슬라이드에는 피처 간 상관관계 분석 결과가 명시되어 있지 않습니다. 추가 분석이 필요할 경우 별도 검토가 요구됩니다.  

Q2) 데이터 수집 기간은 어떻게 되나요?  
A2) 슬라이드 텍스트에는 구체적인 수집 기간이 명시되어 있지 않습니다. 출처 링크(www.kamp-ai.kr)에서 추가 확인이 필요합니다.

---

## Slide 6 (page=5)

- 슬라이드 대본:  
"현재 데이터 분포도에서 세 가지 주요 특징을 확인할 수 있습니다. 첫째, 피처별 값의 범위가 수백 배 이상 차이 나며, 둘째, 다수의 피처가 한쪽으로 치우친 비대칭 분포를 보입니다. 셋째, 일부 피처는 단일 값만 존재해 정보량이 없습니다. 이러한 문제로 인해 정규화가 필수적입니다. 스케일이 큰 피처가 모델 학습에 과도한 영향을 미치면 편향된 결과가 발생할 수 있으며, 정규화를 적용하지 않을 경우 경사하강법의 수렴 속도도 크게 저하됩니다. 따라서 데이터 스케일 조정은 모델 성능과 효율성 향상을 위한 핵심 단계입니다."

- 핵심 메시지 3개:  
1. 피처 간 스케일 차이와 비대칭 분포로 인해 정규화가 필요함.  
2. 정규화 미적용 시 모델 편향 및 학습 속도 저하 발생 가능성 있음.  
3. 단일 값 피처는 정보량이 없어 전처리 단계에서 제외 또는 변환 필요.  

- 예상 질문 2개 + 답변:  
Q1) 정규화 방법 중 어떤 기법을 적용할 계획인가요?  
A1) 슬라이드 내 명시된 컨텍스트에는 구체적인 정규화 기법이 언급되지 않았습니다. 데이터 분포와 모델 요구사항에 따라 Min-Max Scaling 또는 Robust Scaling 등을 검토할 예정입니다.  

Q2) 단일 값 피처는 어떻게 처리하나요?  
A2) 정보량이 없는 단일 값 피처는 모델 입력에서 제외하거나, 도메인 지식을 활용해 새로운 파생 변수를 생성하는 방안을 고려 중입니다. (단, 슬라이드에는 처리 방법이 명시되지 않았으므로 추가 분석이 필요함)

---

## Slide 7 (page=6)

- 슬라이드 대본:  
**"03 데이터 분석 및 모델링"** 섹션 중 **"정규화 진행"**에 대해 설명드리겠습니다.  
다양한 범위의 값을 가진 데이터에 **표준화(Standardization)**를 적용했습니다. 평균(u)을 빼고 표준편차(σ)로 나누어 모든 피처가 평균 0, 표준편차 1의 스케일을 갖도록 변환했습니다. 이를 통해 특정 값에 치우치지 않고, 큰 값에 대한 과도한 가중치를 방지하며, 메모리 효율성과 모델 학습 속도 향상을 기대할 수 있습니다.  

- 핵심 메시지 3개:  
1. 표준화 적용으로 모든 피처를 평균 0, 표준편차 1의 스케일로 변환해 균형을 맞췄다.  
2. 큰 값에 대한 과도한 가중치 방지로 모델의 공정성을 확보했다.  
3. 메모리 효율성 및 학습 속도 향상 효과를 기대할 수 있다.  

- 예상 질문 2개 + 답변:  
Q1) 표준화 대신 정규화(Min-Max Scaling)를 사용하지 않은 이유는 무엇인가요?  
A1) 슬라이드에 명시된 내용은 표준화만 언급되어 있습니다. 정규화 적용 여부는 컨텍스트에 없으므로 답변할 수 없습니다.  

Q2) 표준화 후 모델 성능이 얼마나 향상되었나요?  
A2) 슬라이드 및 컨텍스트에 성능 향상 수치나 결과가 제시되지 않아 답변할 수 없습니다.

---

## Slide 8 (page=7)

- 슬라이드 대본:  
**"04 이상치 데이터"**  
박스플롯 분석 결과, Acceleration, Velocity, OutputPower 관련 피처에서 극단값이 다수 확인되었습니다. 특히 X, Y, Z 축에서 Actual/Set 값과 연관된 이상치가 두드러지게 나타났습니다.  

**"04 - 1 이상치 처리 방향"**  
이상치 데이터는 반드시 불량 데이터를 의미하지 않습니다. 설비 이상이나 가공 불량과의 연관성을 분석한 후, 상관관계 기반으로 처리 방향을 결정할 예정입니다. 예를 들어, X_ActualVelocity의 경우 정상 데이터 2,545건 대비 결함 데이터 1,254건에서 이상치가 발생해 추가 검토가 필요합니다.  

- 핵심 메시지 3개:  
1. Acceleration, Velocity, OutputPower 피처에서 다수 이상치 확인  
2. 이상치 처리 시 불량 여부와의 상관관계 분석을 우선 수행  
3. X, Y, Z 축 Actual/Set 값에서 결함 데이터 대비 이상치 비율 높음  

- 예상 질문 2개 + 답변:  
Q1) 이상치 처리 기준은 어떻게 설정했나요?  
A1) 현재 단계에서는 이상치를 무조건 제거하지 않고, 결함 데이터와의 통계적 연관성을 분석해 기준을 마련할 예정입니다.  

Q2) 특정 피처(예: X_OutputCurrent)에서 이상치가 적은 이유는 무엇인가요?  
A2) X_OutputCurrent는 정상/결함 데이터 모두 이상치가 9건으로 동일하게 나타나, 다른 피처 대비 변동성이 낮은 것으로 추정됩니다. 다만, 추가 원인 분석이 필요합니다.

---

## Slide 9 (page=8)

- 슬라이드 대본:  
"현재 슬라이드는 상관계수 분석 결과를 요약합니다. 30개 이상의 피처 쌍에서 절대값 상관계수가 0.9 이상으로 나타났으며, 특히 Set-Actual 계열은 0.99 이상의 매우 강한 상관관계를 보였습니다. 스핀들 전기적 특성 간 상관계수는 0.93~0.98 범위로 높은 편입니다. Set은 설정값, Actual은 실제 응답값을 의미하는데, 정상 상태에서는 Set과 Actual이 거의 일치합니다. 반면 이상 상태에서는 두 값이 달라지며, 이는 제어 오차, 공구 마모, 진동, 부하 이상 등의 가능성을 시사합니다. 즉, Set-Actual 관계는 공정 상태를 직접 반영하는 핵심 지표입니다. 특히 Z_OutputPower와 S_ActualAcceleration은 0.999999의 거의 완벽한 상관성을 보였습니다."

- 핵심 메시지 3개:  
1. Set-Actual 계열은 0.99 이상의 매우 강한 상관관계를 보이며, 이는 공정 상태를 직접 반영한다.  
2. 30개 이상의 피처 쌍에서 |corr| ≥ 0.9로, 다중 피처 간 높은 상관성이 확인되었다.  
3. Set과 Actual의 불일치는 제어 오차, 공구 마모 등 이상 상태의 신호로 활용될 수 있다.  

- 예상 질문 2개 + 답변:  
Q1) "Set-Actual 상관계수가 0.99 이상인데도 이상 상태를 판단할 수 있는 근거는 무엇인가요?"  
A1) "정상 상태에서는 Set과 Actual이 거의 일치하지만, 이상 상태에서는 두 값이 달라집니다. 높은 상관계수는 일반적인 관계를 나타내지만, 실제 데이터에서 편차가 발생하면 이상 상태를 의심할 수 있습니다."  

Q2) "상관계수가 0.9 이상인 피처 쌍이 30개 이상인데, 다중공선성 문제는 어떻게 해결했나요?"  
A2) "슬라이드에는 다중공선성 해결 방법이 명시되지 않았습니다. 다만, Set-Actual 계열과 스핀들 전기적 특성 등 물리적 연관성이 높은 피처들이 주로 포함되어 있어, 도메인 지식 기반 선택이 이루어졌을 것으로 추정됩니다."

---

## Slide 10 (page=9)

- 슬라이드 대본:  
**"06 I 불량 감지 피처 지정" 섹션입니다.**  
불량은 설정값과 실제값의 차이가 클 때 발생하며, 차이가 미미하면 정상으로 판단합니다. 분석 결과, 이상치가 모든 피처에 고르게 분포했고 특정 피처가 두드러지지 않았습니다. 특히 'S_currentError'는 0.3 임계값 기준으로 불량 비율이 58.59%로 가장 높았습니다. 그러나 다른 피처에서도 일부 불량이 확인되어 추가 필터링이 필요합니다.  

- 핵심 메시지 3개:  
1. 불량은 설정값과 실제값의 차이로 정의되며, 임계값 초과 시 결함으로 분류됩니다.  
2. 'S_currentError'가 0.3 임계값에서 가장 높은 불량 비율(58.59%)을 보였습니다.  
3. 모든 피처에서 이상치가 고르게 분포하여 추가 분석이 필요합니다.  

- 예상 질문 2개 + 답변:  
Q1) 다른 피처보다 'S_currentError'의 불량 비율이 유독 높은 이유는 무엇인가요?  
A1) 데이터에 따르면 'S_currentError'는 전류 피드백과 설정값의 차이가 다른 위치/속도 오차보다 크게 나타나는 경향이 있습니다. 임계값 0.3을 초과하는 경우가 많아 상대적으로 불량 비율이 높게 분석되었습니다.  

Q2) 추가 필터링은 어떤 방식으로 진행될 예정인가요?  
A2) 현재 분석에서는 모든 피처의 이상치가 고르게 분포했으므로, 피처 간 상관관계 분석 또는 머신러닝 기반 다중 조건 필터링을 적용할 계획입니다. 단, 구체적인 방법은 추가 검토를 통해 결정될 예정입니다.

---

## Slide 11 (page=10)

- 슬라이드 대본:  
"세 번째 섹션인 데이터 분석 및 모델링 중 주성분 피처 분석 결과를 설명드리겠습니다.  
m_sequence_number는 센서 데이터보다 공정 진행 단계를 직접적으로 나타내는 핵심 변수로, 현재 공정이 어느 단계에 있는지 명확히 표현합니다.  
이 변수에 명시적 가중치를 부여한 결과, 이상 탐지 성능이 0.89에서 0.92로 약 3% 향상되었습니다.  
차트에서도 m_sequence_number가 가장 높은 중요도를 보이며, 공정 맥락 반영의 효과를 입증했습니다."  

- 핵심 메시지 3개:  
1. m_sequence_number는 공정 진행 단계를 직접적으로 표현하는 핵심 변수입니다.  
2. 해당 변수에 가중치 부여 시 이상 탐지 성능이 3% 향상되었습니다.  
3. 피처 중요도 분석에서 m_sequence_number가 최상위 순위를 기록했습니다.  

- 예상 질문 2개 + 답변:  
Q1) 성능 향상 폭이 3%로 상대적으로 작은데, 실제 적용 시 유의미한가요?  
A1) 3%는 작은 수치일 수 있으나, 공정 맥락 변수를 명시적으로 반영한 첫 실험 결과이며, 추가 최적화를 통해 더 큰 효과를 기대할 수 있습니다.  

Q2) m_sequence_number 외에 다른 공정 맥락 변수를 추가한다면 성능이 더 개선될까요?  
A2) 가능성은 있으나, 본 분석에서는 m_sequence_number의 단일 변수 효과만 검증했습니다. 다중 변수 조합 실험은 향후 과제로 고려 중입니다.

---

## Slide 12 (page=11)

- 슬라이드 대본:  
**"데이터 분석 및 모델링" 섹션의 "PCA" 내용을 설명드리겠습니다.  
48개 변수를 17개 주성분으로 축소하여 65% 차원 감소에도 91.37%의 설명력을 유지했습니다.  
주성분 구조를 보면, PC1은 Z·S축 위치/출력, PC2는 Y·Z축 속도, PC3는 X축 위치/출력과 연관되어 있습니다.  
특히 PC1의 Top 5 특징은 Z·S축의 실제/설정 위치, 출력 전류/전압 등이며, 이는 제어 아키텍처와 정합되어 이상 탐지 및 예지 정비 모델에 효과적으로 활용될 수 있습니다.**  

- 핵심 메시지 3개:  
1. 48개 변수를 17개 주성분으로 축소해 65% 차원 감소 및 91.37% 설명력 유지  
2. 주성분(PC1~PC3)이 각각 Z·S축 위치/출력, Y·Z축 속도, X축 위치/출력과 물리적 연관성 있음  
3. 제어 시스템 아키텍처와 정합된 주성분 구조로 이상 탐지·예지 정비 모델 적용 가능  

- 예상 질문 2개 + 답변:  
Q1) **주성분 축소 시 설명력 91.37%가 충분한 수준인가요?**  
A1) **네, 91.37%는 원본 데이터의 90% 이상 정보를 보존한 것으로, 차원 축소와 정보 유지 측면에서 충분히 유의미한 수준입니다.**  

Q2) **PC1~PC3 외 다른 주성분은 어떤 의미를 가지나요?**  
A2) **PC4~PC17은 상대적으로 낮은 기여도를 보이지만, X축 가속도, Y축 출력 전력 등 세부 변수와 연관되어 있습니다. 추가 분석을 통해 잠재적 패턴을 탐색할 수 있습니다.**

---

## Slide 13 (page=12)

- 슬라이드 대본:  
"현재 슬라이드는 t-SNE를 이용한 2D 시각화 결과를 보여줍니다. 분석 결과, 'No' 클래스가 왼쪽에 집중되어 있고 'Yes' 클래스와 부분적으로 혼재되어 있습니다. 이는 선형 모델인 로지스틱 회귀나 선형 SVM보다 트리 기반 모델(XGBoost, RandomForest)이 더 적합할 수 있음을 시사합니다. 트리 모델은 지역적 패턴과 축 평행 분할에 강점이 있어 비선형 구조를 잘 포착할 수 있습니다. 또한 MLP 같은 신경망도 비선형 경계 학습에 효과적이므로 대안으로 고려할 수 있습니다. *t-SNE는 고차원 데이터를 2D로 압축해 시각화하는 기법임을 참고해 주세요."

- 핵심 메시지 3개:  
1. t-SNE 시각화에서 'No' 클래스가 좌측에 집중, 'Yes'와 부분적 혼재  
2. 선형 모델보다 트리 기반 모델(XGBoost, RandomForest)이 비선형 구조에 적합  
3. MLP도 비선형 경계 학습으로 트리 모델의 대안 가능  

- 예상 질문 2개 + 답변:  
Q1) t-SNE 시각화에서 클래스 분포가 모델 선택에 어떻게 영향을 미치나요?  
A1) 선형 모델은 직선 경계만 학습 가능하지만, t-SNE 결과가 비선형적 분포를 보이므로 트리 기반이나 MLP가 복잡한 패턴을 더 잘 포착할 수 있습니다.  

Q2) 왜 XGBoost나 RandomForest가 이 데이터에 적합하다고 판단했나요?  
A2) 두 모델은 지역적 패턴을 인식하는 축 평행 분할에 강점이 있어, 혼재된 클래스 구조를 효과적으로 분류할 수 있기 때문입니다.

---

## Slide 14 (page=13)

- 슬라이드 대본:  
"데이터 분석 및 모델링 부분을 설명드리겠습니다.  
주요 모델로는 로지스틱 회귀, SVM, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅을 사용했고, 전처리 방법으로 정규화, PCA, 원본 데이터를 비교했습니다.  
성능 비교 결과, 정규화 후 SVM(RBF)이 89.3%로 가장 높은 정확도를 보였으며, PCA 적용 시 랜덤 포레스트가 89.1%로 우수했습니다.  
핵심 목표는 정상 상태 식별과 오탐 최소화였습니다. 테스트셋도 정상 데이터 위주로 평가하는 것이 합리적이며, 논문 'CNC 가공 결함 예측 모델'을 참고했습니다."  

- 핵심 메시지 3개:  
1. 정규화 + SVM(RBF) 조합이 89.3% 최고 정확도 달성  
2. PCA 적용 시 랜덤 포레스트 성능(89.1%)이 원본 대비 3.8%p 향상  
3. 정상 상태 식별과 오탐 감소가 모델 평가의 핵심 기준  

- 예상 질문 2개 + 답변:  
Q1) 정규화와 PCA 중 어떤 전처리 방법이 더 효과적이라고 볼 수 있나요?  
A1) 목적에 따라 다릅니다. 정규화는 SVM과 로지스틱 회귀에서, PCA는 랜덤 포레스트와 함께 사용 시 높은 성능을 보였습니다.  

Q2) 오탐 최소화를 위해 특별히 고려한 평가 지표가 있나요?  
A2) 슬라이드에 명시된 대로 정상 데이터 위주의 테스트셋 구성과 혼동 행렬 분석을 통해 오탐률을 집중 평가했습니다. (참고: Confusion Matrix 차트)

---

## Slide 15 (page=14)

- 슬라이드 대본:  
"하이퍼 파라미터 튜닝을 통해 모델 성능을 크게 향상시켰습니다. GridSearchCV로 로지스틱 회귀와 SVM을 최적화했고, AUC가 0.89에서 0.97로 약 8% 상승했습니다. RandomizedSearchCV는 랜덤 포레스트와 그래디언트 부스팅에 적용해 탐색 효율성을 높였으며, 특히 랜덤 포레스트는 최대 깊이 10, 최소 샘플 리프 2 등의 파라미터로 최고 AUC 0.974를 기록했습니다. 표에서 볼 수 있듯, 스케일링과 PCA 적용 시 대부분의 모델에서 성능 개선이 확인되었습니다."

- 핵심 메시지 3개:  
1. GridSearchCV로 로지스틱 회귀와 SVM 최적화, AUC 8% 향상  
2. RandomizedSearchCV로 랜덤 포레스트 최고 AUC 0.974 달성  
3. 스케일링 및 PCA 적용 시 전반적 모델 성능 개선  

- 예상 질문 2개 + 답변:  
Q1) GridSearchCV와 RandomizedSearchCV를 모델별로 다르게 적용한 이유가 있나요?  
A1) 네, GridSearchCV는 작은 파라미터 공간에서 전수 탐색이 가능한 로지스틱 회귀와 SVM에 적합했고, RandomizedSearchCV는 넓은 범위의 파라미터를 효율적으로 탐색해야 하는 랜덤 포레스트와 그래디언트 부스팅에 더 효과적이기 때문입니다.  

Q2) PCA 적용 시 성능이 향상된 이유는 무엇인가요?  
A2) PCA는 차원 축소를 통해 노이즈를 줄이고 주요 특징을 강조함으로써 모델의 일반화 성능을 높였기 때문입니다. 표에서 PCA 적용 시 대부분의 모델에서 AUC가 상승한 것을 확인할 수 있습니다.

---

## Slide 16 (page=15)

- 슬라이드 대본:  
"이번 섹션에서는 데이터 분석 및 모델링 파이프라인을 설명드리겠습니다. 먼저 데이터 정의 및 전처리 단계에서는 실제값과 설정값의 차이(S_currentError)를 핵심 피처로 선정하고, 임계값 0.3을 적용해 불량을 판정했습니다. 이후 정규화 수행과 PCA, t-SNE를 통한 차원 축소로 데이터 효율성을 높였습니다. 모델 적용 단계에서는 로지스틱 회귀, SVM, 랜덤 포레스트, CatBoost, LightGBM 등 다양한 알고리즘을 비교 평가했습니다. 특히 하이퍼파라미터 최적화 시 선형 모델에는 GridSearchCV, 트리 기반 모델에는 RandomizedSearchCV를 사용해 5-Fold 교차 검증과 ROC-AUC 기준으로 최적 파라미터를 선택했습니다. 이를 통해 결함 유닛 예측 정확도를 극대화했습니다."

- 핵심 메시지 3개:  
1. S_currentError를 핵심 피처로 선정하고 임계값 0.3 적용  
2. PCA/t-SNE 차원 축소와 정규화로 데이터 전처리 최적화  
3. GridSearchCV/RandomizedSearchCV를 활용한 모델별 하이퍼파라미터 최적화  

- 예상 질문 2개 + 답변:  
Q1) S_currentError 외에 다른 피처도 고려했나요?  
A1) 슬라이드에 명시된 대로 S_currentError가 핵심 피처로 선정되었으며, 다른 피처는 차원 축소 단계에서 처리되었습니다.  

Q2) 모델 선택 시 성능 평가 기준은 무엇이었나요?  
A2) ROC-AUC를 주요 평가 기준으로 사용했으며, 5-Fold 교차 검증을 통해 모델의 일반화 성능을 검증했습니다.

---

## Slide 17 (page=16)

- 슬라이드 대본:  
"정부형 스마트공장 구축사업은 중소·중견기업의 스마트공장 도입 및 고도화를 지원하는 사업입니다. 정부는 구축비용의 일부를 보조하며, 기업의 현재 수준을 진단한 후 맞춤형 솔루션과 AI 기술 접목을 중점적으로 지원합니다. 신청은 사업 계획서 작성 후 가능하며, 데이터 집계 포인트 예시와 같이 MES 서버, 패널 PC, 바코드 스캐너 등 장비 구축 시 데이터 수집·분석 계획을 포함해야 합니다. 표준연계 선택 시 OPC-UA 통신표준 활용 사례처럼 MES와 장비 간 연계 방안도 기술할 수 있습니다."

- 핵심 메시지 3개:  
1. 정부형 스마트공장 구축사업은 중소·중견기업의 스마트공장 도입 비용 일부를 보조한다.  
2. 기업 진단 후 맞춤형 솔루션 및 AI 기술 접목을 통해 고도화를 지원한다.  
3. 데이터 수집·분석 계획과 표준연계 방안(예: OPC-UA)을 기술해 신청할 수 있다.  

- 예상 질문 2개 + 답변:  
Q1) 사업 신청 시 반드시 포함해야 하는 내용은 무엇인가요?  
A1) 사업 계획서에 기업의 현재 수준 진단 결과, 맞춤형 솔루션 및 AI 기술 접목 방안, 데이터 수집·분석 계획(예: MES 서버, 장비 목록)을 포함해야 합니다.  

Q2) 표준연계 선택 시 가점을 받으려면 어떻게 해야 하나요?  
A2) OPC-UA 통신표준 활용 사례처럼 MES와 장비 간 연계 방안을 구체적으로 기술하면 표준가점을 신청할 수 있습니다. 단, 선택사항이므로 필수 항목은 아닙니다.

---

## Slide 18 (page=17)

- 슬라이드 대본:  
"정부형 스마트공장 구축사업에서 가산점을 받으려면 OPC-UA 기반 실시간 데이터 연동이 필수입니다. OPC-UA는 국제 표준 프로토콜로 신뢰성이 높아 정부 과제 평가 시 유리합니다. 가산점 획득 조건은 크게 두 가지인데요. 첫째, OPC-UA를 통해 장비 데이터를 MES와 연계해야 합니다. 둘째, 표준 통신프로토콜을 활용한 시스템을 구축해야 합니다. 이를 증명하려면 OPC-UA 게이트웨이 시험성적서나 현장 작동 확인, MES 데이터 전송 확인 자료가 필요합니다. 또한, OPC-UA 게이트웨이 적용 시 기초·고도화 단계별로 최대 1억 원까지 지원금을 받을 수 있습니다."

- 핵심 메시지 3개:  
1. OPC-UA는 정부 과제 가산점 획득의 필수 조건이며 국제 표준 프로토콜로 신뢰성이 높음  
2. 가산점 획득을 위해 OPC-UA를 통한 장비 데이터 MES 연계 및 표준 통신프로토콜 시스템 구축이 필요  
3. OPC-UA 적용 시 기초·고도화 단계별로 최대 1억 원까지 지원금 혜택 제공  

- 예상 질문 2개 + 답변:  
Q1) OPC-UA 외에 다른 프로토콜도 가산점 적용 가능한가요?  
A1) 슬라이드 기준으로는 OPC-UA만 명시되어 있습니다. 다른 프로토콜에 대한 가산점 여부는 별도 확인이 필요합니다.  

Q2) 지원금 신청 시 필요한 서류는 무엇인가요?  
A2) OPC-UA 게이트웨이 시험성적서 또는 현장 작동 확인서, MES 데이터 전송 확인 자료가 필수입니다. 지원 단계별 상세 서류는 사업 공고문을 참조해야 합니다.

---

## Slide 19 (page=18)

- 슬라이드 대본:  
"이번 프로젝트의 기대 효과는 크게 세 가지입니다. 첫째, 실시간 기계 작동 모니터링으로 이상 감지와 불량 예방이 가능해집니다. 둘째, 설비 조건을 사전에 최적화하여 품질 관리를 강화할 수 있습니다. 셋째, 데이터 기반 검사로 품질 일관성을 확보할 수 있습니다. 향후 계획으로는 모델 정확도 향상 작업을 진행하고, 지역특화형 스마트공장 사업을 지원할 예정입니다. 또한 추가 시스템 구축 없이 데이터 제공만으로 분석 및 모델 학습이 가능한 환경을 구축할 계획입니다."

- 핵심 메시지 3개:  
1. 실시간 모니터링으로 불량 예방 및 품질 관리 강화  
2. 데이터 기반 품질 일관성 확보  
3. 추가 시스템 없이 데이터만으로 분석/학습 가능한 환경 구축  

- 예상 질문 2개 + 답변:  
Q1) "모델 정확도 향상을 위한 구체적인 계획은 무엇인가요?"  
A1) "현재 데이터 품질 검증과 알고리즘 최적화를 병행하며, 지속적인 테스트를 통해 정확도를 개선할 예정입니다."  

Q2) "지역특화형 스마트공장 지원 시 어떤 기준을 적용하나요?"  
A2) "지역 산업 특성과 설비 현황을 분석해 맞춤형 솔루션을 제공하며, 데이터 호환성을 최우선으로 고려합니다."

---

## Slide 20 (page=19)

- 슬라이드 대본:  
"지금까지 설명한 과정을 다시 한번 정리해 보겠습니다. 설비 데이터를 수집하고 AI로 분석한 뒤 이상을 감지해 불량을 조기에 발견하는 체계를 구축했습니다. 그 결과, AI로 인해 사람의 검사 업무가 보조되거나 대체될 수 있게 되었고, 미세한 불량을 조기에 발견해 원가 절감 효과를 얻었습니다. 또한 품질 관리 체계가 고도화되면서 기업의 경쟁력 강화로 이어졌습니다. 이 프로젝트가 품질 관리의 새로운 가능성을 열었다고 볼 수 있겠습니다."

- 핵심 메시지 3개:  
1. AI 분석을 통해 설비 데이터의 이상 감지 및 불량 조기 검출이 가능해졌다.  
2. 미세 불량 조기 발견으로 원가 절감과 품질 신뢰도 향상을 달성했다.  
3. AI 기반 품질 관리 체계 고도화로 기업 경쟁력이 강화되었다.  

- 예상 질문 2개 + 답변:  
Q1) AI 분석만으로 모든 검사 업무를 완전히 대체할 수 있나요?  
A1) 현재 단계에서는 AI가 사람의 검사 업무를 보조하거나 부분적으로 대체하는 수준입니다. 특히 미세 불량 검출과 같은 반복적 업무에 효과적이며, 최종 판단은 여전히 인간의 검토가 필요할 수 있습니다.  

Q2) 품질 관리 체계 고도화가 구체적으로 어떤 변화를 가져왔나요?  
A2) 기존에는 수동 검사에 의존하던 프로세스를 AI 분석을 통해 실시간 모니터링과 예측 가능한 시스템으로 전환했습니다. 이로 인해 불량 발생 전 사전 조치가 가능해지고, 전체적인 품질 관리 효율성이 개선되었습니다.

---

## Slide 21 (page=20)

- 슬라이드 대본:  
"안녕하세요. 이번 프로젝트의 핵심 멤버들을 소개합니다. 팀장 이상아 님은 기존 과제를 분석해 '불량률 감소'라는 실질적인 목표로 재설정하고, 프로젝트 전반을 총괄 관리했습니다. 팀원 박지완 님은 데이터 추출부터 정제·통합까지 분석 환경 구축을 담당했으며, 노규진 님은 통계 모델을 활용해 불량 발생의 핵심 변수와 상관관계를 규명했습니다. 김우영 님은 데이터 자료 조사와 보고서 작성을 지원하며 프로젝트를 뒷받침했습니다. 각 멤버의 전문성이 결합되어 목표 달성에 기여할 수 있었습니다."

- 핵심 메시지 3개:  
1. 팀장 이상아는 과제 목표 재설정 및 프로젝트 총괄 관리 역할을 수행했다.  
2. 팀원 박지완은 데이터 전처리 과정을 통해 분석 환경을 구축했다.  
3. 팀원 노규진은 통계 모델을 활용해 불량률 영향 변수를 규명했다.  

- 예상 질문 2개 + 답변:  
Q1) 김우영 님의 구체적인 지원 내용은 무엇인가요?  
A1) 김우영 님은 스마트 공장 관련 자료 조사와 문서 작성 보조, 최종 보고서 작성을 담당했습니다.  

Q2) 불량률 감소를 위해 어떤 전략이 수립되었나요?  
A2) 슬라이드 내 구체적인 전략 내용은 제시되지 않았으나, 데이터 기반 분석 환경 구축과 핵심 변수 규명을 통해 접근한 것으로 보입니다. (컨텍스트 한계 내 답변)

---

## Slide 22 (page=21)

- 슬라이드 대본:  
"이번 프로젝트에서 팀원들은 데이터 분석이 현장 문제 해결의 실질적 도구임을 체감했습니다. 이상아 씨는 이론과 현장의 결합을 통해 불량 원인 분석과 공정 개선에 기여하며 데이터 분석의 실용성을 깨달았고, 박지완 씨는 데이터 분석이 불량률 개선과 생산성 향상으로 직접 연결되는 경험을 통해 실무 역량의 중요성을 확인했습니다. 노규진 씨는 현장 데이터 분석을 통해 이론이 아닌 현장 중심의 문제 해결 방식을 터득했으며, 김우영 씨는 협업을 통한 실무 역량 강화의 필요성을 느꼈습니다. 이처럼 데이터 분석은 단순한 기술이 아닌 현장 문제 해결의 핵심 수단임을 배웠습니다."

- 핵심 메시지 3개:  
1. 데이터 분석은 현장 문제 해결을 위한 실질적인 도구이며, 이론과 실무의 결합이 중요하다.  
2. 현장 데이터 분석을 통해 불량률 감소와 생산성 향상 등 구체적인 성과를 도출할 수 있다.  
3. 협업을 통한 실무 역량 강화가 개인 작업보다 더 큰 성과를 이끌어낸다.  

- 예상 질문 2개 + 답변:  
Q1) 데이터 분석 과정에서 가장 어려웠던 점은 무엇이었나요?  
A1) 현장 데이터의 불완전성과 실제 공정 조건과의 차이를 극복하는 것이 어려웠습니다. 이를 해결하기 위해 현장 담당자와 지속적으로 소통하며 데이터를 보완했습니다.  

Q2) 협업 과정에서 가장 중요한 요소는 무엇이라고 생각하시나요?  
A2) 팀원 간의 명확한 역할 분담과 지속적인 소통이 핵심이었습니다. 각자의 전문성을 존중하면서도 공통된 목표를 위해 협력하는 태도가 중요했습니다.

---

